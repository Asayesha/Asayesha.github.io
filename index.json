[{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\n Don’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution.    ","permalink":"https://Asayesha.github.io/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Intro Doesn't matter whether it's a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\n First it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026rdquo; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on.  Once you implement SSL certificates on your server you'll want to require secure connections using Apache's rewrite module. Now I won't dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\n Creating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026rdquo; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users)  The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026lsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026lsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you'll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You'll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that's easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You'll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://Asayesha.github.io/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":"To understand how safe is the city of Austin, we set out to analyse Austin crime data and dig deeper into why crimes in Austin increased drastically in the year 2018. The data showed that non-violent crimes have been increasing but violent crimes were decreasing.The average processing time for violent crimes is 44 days where as for non-violetn crimes is 30 days.\n","permalink":"https://Asayesha.github.io/projects/projects/5austin-crimes/","tags":["Python","Seaborn","Bokeh"],"title":"Austin Crimes"},{"categories":null,"contents":"Marketing is all about want you want your customers to associte your brand with.User generated content can give insights on consumers\u0026rsquo; perceptions. Car reviews data scraped from Edmundsforum helped understand most discussed car brands and most discussed attributes of cars using NLP. Evaluated associations between brands using lift analysis and visualised it using Multidimesional (MDS) plot.\n","permalink":"https://Asayesha.github.io/projects/projects/7carbrand/","tags":["Web scrapping","NLP","Lift analysis"],"title":"Car Brand Association Analysis"},{"categories":null,"contents":"Recent global phenomena related to climate change, call for a new strategy to collectively move towards sustainable energy and reduce our carbon footprint. In one such effort, building owners are incentivised to improve building efficiencies to reduce operating costs and emissions. In this project, building energy consumption is predicted which can then be compared to the actual running costs and decide upon the incentives. Operating costs from over 1000 building over a 3 year timeframe is used to build the prediction model.\n","permalink":"https://Asayesha.github.io/projects/projects/4energy-consumption-prediction/","tags":["Python","Plotly","Bokeh","Time Series Analysis","lightGBM"],"title":"Energy Consumption Prediction"},{"categories":null,"contents":"A consulting project for a solar energy based start-up to understand potential customers based on customer sign-ups. The goal of this project was help the management understand features influencing customer sign-ups - Recommended marketing channels and optimization of mobile website. Also advised a third party vendor for easier access of data for future use.\n","permalink":"https://Asayesha.github.io/projects/projects/1google-analytics/","tags":["Python","Google Analytics","BigQuery","Google Vision","User Engagement Analysis","Logistic Regression","Random Forest","XGboost","K-prototype"],"title":"Google Analytics"},{"categories":null,"contents":"Considering that in 2014 social users posted an average of 1.8 billion photos to the internet daily and the growth of image-centric platforms like Instagram, Snapchat and Pinterestmakes analyzing visual data also very important to understand your audience.We tried to answer What should National Geographic do to increase engagement on its Instagram page?. Image analytics using LDA topic modeling on scraped data from the Instagram Natgeohandle, gave some insights into types of posts that are least and most engaging.\n","permalink":"https://Asayesha.github.io/projects/projects/3instagram-engagement/","tags":["Python","User Engagement Improvement","Google Vision Cloud","WebScraping","NewsFeed Analysis","Topic modelling","Latent Dirichlet allocation","TF-IDF","Logistic regression"],"title":"Instagram User Engagement"},{"categories":null,"contents":"Today in the world of personalized marketing, it is important to understand each customer and target them accordingly. The task of analyzing customer behaviour from humongous data is a challenging one and this project attempts to recommend books to users based on their given ratings of other books. Collaborative filtering methods on books clustered using K-means improved accuracy and a reccomendation of mixture of books from different clusters can help solve the long tail problem and increase customer satisfaction and experience.\n","permalink":"https://Asayesha.github.io/projects/projects/2book-recommendation/","tags":["Python","Recommendation system","User-based collaborative Filtering","Item -based collaborative Filtering","K-Means Clustering"],"title":"Recommendation Engine"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ] ","permalink":"https://Asayesha.github.io/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":"Twitter will increasing followers can be a social platform for CEOs to connect directly with customers. Analysed tweeting styles of CEOs from different sectors to ascertain the characteristics that make them influential. Stock price analysis (regression) showed influential CEOs can actually impact stock prices through tweets. Influential CEOs can leverage Twitter to turn negative sentiments of the crowd to positive ones and affect the market.\n","permalink":"https://Asayesha.github.io/projects/projects/8twitterceo/","tags":["Python","NLTK","spacy","tweepy","gensim","textblob"],"title":"Twitter CEO engagement - NLP"},{"categories":null,"contents":"Fatality Analysis Reporting System (FARS) was created in the United States by the National Highway Traffic Safety Administration (NHTSA) to provide an overall measure of highway safety. It contains data on a census of fatal traffic crashes within the 50 States, the District of Columbia, and Puerto Rico.To be included in FARS, a crash must result in the death of a person (occupant of a vehicle or a non-occupant) within 30 days of the crash. Surprisingly, 47% of the fatal crashes happened during the day and just 27% of the accidents where due to drink drivers.\n","permalink":"https://Asayesha.github.io/projects/projects/6us-traffic/","tags":["Python","Databricks","Big Query","Google Colab","Plotly","seaborn"],"title":"US Traffic Fatalities Analysis"}]